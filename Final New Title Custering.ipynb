{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cde09df",
   "metadata": {},
   "source": [
    "# NEW TITLE CLUSTERING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e8e3ab",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Project Flow\n",
    "\n",
    "* Text Data Cleaning\n",
    "* Feature Extraction by Count Vectorizer, TFIDF, BERT\n",
    "* Clustering Algorithm - Kmeans and Spectral Clustering\n",
    "* Evaluation Metrics - Silhouette Score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0e5c1aea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T08:51:05.718996Z",
     "start_time": "2022-03-17T08:50:46.710286Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Text Pre-processing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "# Feature Extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "wordnet= WordNetLemmatizer()\n",
    "stop_word = stopwords.words(\"english\")\n",
    "nlp= spacy.load('en_core_web_sm')\n",
    "from nltk.cluster import KMeansClusterer\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans,KMeans,SpectralClustering\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "#evaluation\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6a2bbca2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T08:49:02.505768Z",
     "start_time": "2022-03-17T08:49:02.493736Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# text data\n",
    "data ={\"PM Has Tremendous Vigour: Shashi Tharoor Credits Him For UP Polls Win\",\n",
    "       \"You have seen Priyanka Gandhi everywhere’: Shashi Tharoor on Congress performance in 5 state elections\",\n",
    "      \"Shashi Tharoor explains why Congress is worth reviving as crucial meet is on\",\n",
    "       \"Bhagwant Mann's Swearing-In Ceremony LIVE | Punjab's New Chief Minister | India Today LIVE\",\n",
    "       \"Bhagwant Mann swearing-in: ‘He was always in my prayers, will always be..,’ says ex-wife; children reach India to attend ceremony\",\n",
    "       \"Punjab CM swearing-in LIVE updates: Bhagwant Mann sworn in as chief minister\",\n",
    "       \"Bhagwant Mann Swearing-In Live: AAP Leader Takes Oath As Punjab Chief Minister\",\n",
    "       \"Govt sounds Covid alert, calls for strict vigil as cases rise elsewhere\",\n",
    "       \"Centre Rings Alarm Amid Covid Comeback in China, Calls for Genome Sequencing, Surveillance At High-Level Meet\",\n",
    "       \"Covid-19: Mansukh Mandaviya tells officials to stay alert, enhance surveillance\",\n",
    "       \"Fourth wave of Covid-19 in China, Hong Kong raises alarm bells for India, check more\"\n",
    "      }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e585885",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Count Vectorizer + Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9f49881c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T08:47:55.507900Z",
     "start_time": "2022-03-17T08:47:55.481969Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Similarity(text):\n",
    "    \n",
    "    text = set(text)\n",
    "\n",
    "    df= pd.DataFrame(data=text)\n",
    "    df=df.rename(columns={0:\"text\"})\n",
    "    \n",
    "    corpus = []\n",
    "\n",
    "    for i in range (0, len (df)):\n",
    "        # remvome puntuation \n",
    "        clean_text = re.sub('[^a-zA-Z]',' ',df[\"text\"][i])\n",
    "\n",
    "        # lower case \n",
    "        clean_text = clean_text.lower()\n",
    "\n",
    "        # split into token\n",
    "        clean_text = clean_text.split()\n",
    "\n",
    "        # join the text for leemitization\n",
    "        clean_text = nlp(\" \".join(clean_text))\n",
    "        # lemmitization\n",
    "        clean_text = [token.lemma_ for token in clean_text]\n",
    "\n",
    "        #stop word removal\n",
    "        clean_text = [word for word in clean_text if word not in stop_word]\n",
    "\n",
    "        # Joining the words in sentences\n",
    "        clean_text = ' '.join(clean_text)\n",
    "        corpus.append(clean_text)\n",
    "    \n",
    "    # Feature Extraction by TFIDF\n",
    "    count = CountVectorizer()\n",
    "    corpus_tfidf= count.fit_transform(corpus).toarray()\n",
    "    \n",
    "    sil_score_max = -1 #this is the minimum possible score\n",
    "\n",
    "    #to get the best clusters \n",
    "    for n_clusters in range(2,len(df)):\n",
    "\n",
    "        cls= KMeans(n_clusters= n_clusters,random_state=7)\n",
    "\n",
    "        cls.fit_transform(corpus_tfidf)\n",
    "\n",
    "        labels = cls.predict(corpus_tfidf)\n",
    "\n",
    "        sil_score = silhouette_score(corpus_tfidf,labels=labels)\n",
    "\n",
    "        if sil_score > sil_score_max:\n",
    "            sil_score_max = sil_score\n",
    "            best_cluster = n_clusters\n",
    "    \n",
    "    # use the best cluster number for Kmean model\n",
    "    cls = KMeans(n_clusters=best_cluster,random_state=7)\n",
    "    \n",
    "    cls.fit_transform(corpus_tfidf)\n",
    "    \n",
    "    cls.predict(corpus_tfidf)\n",
    "    \n",
    "    # labels for the clusters \n",
    "    df['Cluster']= cls.labels_\n",
    "    \n",
    "    return df.sort_values(by=[\"Cluster\"]), print(\"Best Cluster - {} Silhouette Score - {}\".format (best_cluster,sil_score_max))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f1df3ebc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T08:47:57.336172Z",
     "start_time": "2022-03-17T08:47:56.413584Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cluster - 3 Silhouette Score - 0.17376330419965946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                                 text  Cluster\n",
       " 0   Bhagwant Mann's Swearing-In Ceremony LIVE | Pu...        0\n",
       " 5   Punjab CM swearing-in LIVE updates: Bhagwant M...        0\n",
       " 10  Bhagwant Mann Swearing-In Live: AAP Leader Tak...        0\n",
       " 2   PM Has Tremendous Vigour: Shashi Tharoor Credi...        1\n",
       " 3   Shashi Tharoor explains why Congress is worth ...        1\n",
       " 4                  Do you know what you are fight for        1\n",
       " 6   Centre Rings Alarm Amid Covid Comeback in Chin...        1\n",
       " 7   Fourth wave of Covid-19 in China, Hong Kong ra...        1\n",
       " 8   Govt sounds Covid alert, calls for strict vigi...        1\n",
       " 9   You have seen Priyanka Gandhi everywhere’: Sha...        1\n",
       " 11  Covid-19: Mansukh Mandaviya tells officials to...        1\n",
       " 1   Bhagwant Mann swearing-in: ‘He was always in m...        2,\n",
       " None)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Similarity(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68989014",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T08:42:59.811282Z",
     "start_time": "2022-03-17T08:42:59.806295Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## Countvectorizer + Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ac40fc3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T08:48:05.314782Z",
     "start_time": "2022-03-17T08:48:05.283906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Similarity(text):\n",
    "    text = set (text)\n",
    "\n",
    "    df= pd.DataFrame(data=text)\n",
    "    df=df.rename(columns={0:\"text\"})\n",
    "    \n",
    "    corpus = []\n",
    "\n",
    "    for i in range (0, len (df)):\n",
    "        # remvome puntuation \n",
    "        clean_text = re.sub('[^a-zA-Z]',' ',df[\"text\"][i])\n",
    "\n",
    "        # lower case \n",
    "        clean_text = clean_text.lower()\n",
    "\n",
    "        # split into token\n",
    "        clean_text = clean_text.split()\n",
    "\n",
    "        # join the text for leemitization\n",
    "        clean_text = nlp(\" \".join(clean_text))\n",
    "        # lemmitization\n",
    "        clean_text = [token.lemma_ for token in clean_text]\n",
    "\n",
    "        #stop word removal\n",
    "        clean_text = [word for word in clean_text if word not in stop_word]\n",
    "\n",
    "        # Joining the words in sentences\n",
    "        clean_text = ' '.join(clean_text)\n",
    "        corpus.append(clean_text)\n",
    "    \n",
    "    # Feature Extraction by TFIDF\n",
    "    tfidf = CountVectorizer()\n",
    "    corpus_tfidf= tfidf.fit_transform(corpus).toarray()\n",
    "    \n",
    "    sil_score_max = -1 #this is the minimum possible score\n",
    "\n",
    "    for n_clusters in range(2,len(df)):\n",
    "\n",
    "        cls= SpectralClustering(n_clusters= n_clusters,assign_labels='discretize',random_state=7).fit(corpus_tfidf)\n",
    "\n",
    "        labels = cls.labels_\n",
    "\n",
    "        sil_score = silhouette_score(corpus_tfidf,labels=labels)\n",
    "\n",
    "        if sil_score > sil_score_max:\n",
    "            sil_score_max = sil_score\n",
    "            best_cluster = n_clusters\n",
    "             \n",
    "    # use the best cluster for Spectral Clustering model\n",
    "    cls = SpectralClustering(n_clusters=best_cluster,assign_labels='discretize',random_state=7).fit(corpus_tfidf) \n",
    "    \n",
    "    \n",
    "    # labels for the clusters \n",
    "    df['Cluster']= cls.labels_\n",
    "    \n",
    "    return df.sort_values(by=[\"Cluster\"]), print(\"Best Cluster - {} Silhouette Score - {}\".format (best_cluster,sil_score_max))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e7ec474c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T08:48:06.467585Z",
     "start_time": "2022-03-17T08:48:06.209135Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cluster - 2 Silhouette Score - 0.1558060818857329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                                 text  Cluster\n",
       " 0   Bhagwant Mann's Swearing-In Ceremony LIVE | Pu...        0\n",
       " 5   Punjab CM swearing-in LIVE updates: Bhagwant M...        0\n",
       " 10  Bhagwant Mann Swearing-In Live: AAP Leader Tak...        0\n",
       " 1   Bhagwant Mann swearing-in: ‘He was always in m...        1\n",
       " 2   PM Has Tremendous Vigour: Shashi Tharoor Credi...        1\n",
       " 3   Shashi Tharoor explains why Congress is worth ...        1\n",
       " 4                  Do you know what you are fight for        1\n",
       " 6   Centre Rings Alarm Amid Covid Comeback in Chin...        1\n",
       " 7   Fourth wave of Covid-19 in China, Hong Kong ra...        1\n",
       " 8   Govt sounds Covid alert, calls for strict vigi...        1\n",
       " 9   You have seen Priyanka Gandhi everywhere’: Sha...        1\n",
       " 11  Covid-19: Mansukh Mandaviya tells officials to...        1,\n",
       " None)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Similarity(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2602ae6f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TFIDF + Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5970b041",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T08:49:04.939536Z",
     "start_time": "2022-03-17T08:49:04.921540Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Similarity(text):\n",
    "    \n",
    "    text = set(text)\n",
    "\n",
    "    df= pd.DataFrame(data=text)\n",
    "    df=df.rename(columns={0:\"text\"})\n",
    "    \n",
    "    corpus = []\n",
    "\n",
    "    for i in range (0, len (df)):\n",
    "        # remvome puntuation \n",
    "        clean_text = re.sub('[^a-zA-Z]',' ',df[\"text\"][i])\n",
    "\n",
    "        # lower case \n",
    "        clean_text = clean_text.lower()\n",
    "\n",
    "        # split into token\n",
    "        clean_text = clean_text.split()\n",
    "\n",
    "        # join the text for leemitization\n",
    "        clean_text = nlp(\" \".join(clean_text))\n",
    "        # lemmitization\n",
    "        clean_text = [token.lemma_ for token in clean_text]\n",
    "\n",
    "        #stop word removal\n",
    "        clean_text = [word for word in clean_text if word not in stop_word]\n",
    "\n",
    "        # Joining the words in sentences\n",
    "        clean_text = ' '.join(clean_text)\n",
    "        corpus.append(clean_text)\n",
    "    \n",
    "    # Feature Extraction by TFIDF\n",
    "    tfidf = TfidfVectorizer()\n",
    "    corpus_tfidf= tfidf.fit_transform(corpus).toarray()\n",
    "    \n",
    "    sil_score_max = -1 #this is the minimum possible score\n",
    "\n",
    "    #to get the best clusters \n",
    "    for n_clusters in range(2,len(df)):\n",
    "\n",
    "        cls= KMeans(n_clusters= n_clusters,random_state=7)\n",
    "\n",
    "        cls.fit_transform(corpus_tfidf)\n",
    "\n",
    "        labels = cls.predict(corpus_tfidf)\n",
    "\n",
    "        sil_score = silhouette_score(corpus_tfidf,labels=labels)\n",
    "\n",
    "        if sil_score > sil_score_max:\n",
    "            sil_score_max = sil_score\n",
    "            best_cluster = n_clusters\n",
    "    \n",
    "    # use the best cluster number for Kmean model\n",
    "    cls = KMeans(n_clusters=best_cluster,random_state=7)\n",
    "    \n",
    "    cls.fit_transform(corpus_tfidf)\n",
    "    \n",
    "    cls.predict(corpus_tfidf)\n",
    "    \n",
    "    # labels for the clusters \n",
    "    df['Cluster']= cls.labels_\n",
    "    \n",
    "    return df.sort_values(by=[\"Cluster\"]), print(\"Best Cluster - {} Silhouette Score - {}\".format (best_cluster,sil_score_max))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "54026801",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T08:49:06.075939Z",
     "start_time": "2022-03-17T08:49:05.370278Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cluster - 4 Silhouette Score - 0.12301263706380686\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                                 text  Cluster\n",
       " 1   Bhagwant Mann swearing-in: ‘He was always in m...        0\n",
       " 0   Bhagwant Mann's Swearing-In Ceremony LIVE | Pu...        1\n",
       " 5   Punjab CM swearing-in LIVE updates: Bhagwant M...        1\n",
       " 9   Bhagwant Mann Swearing-In Live: AAP Leader Tak...        1\n",
       " 4   Centre Rings Alarm Amid Covid Comeback in Chin...        2\n",
       " 6   Fourth wave of Covid-19 in China, Hong Kong ra...        2\n",
       " 7   Govt sounds Covid alert, calls for strict vigi...        2\n",
       " 10  Covid-19: Mansukh Mandaviya tells officials to...        2\n",
       " 2   PM Has Tremendous Vigour: Shashi Tharoor Credi...        3\n",
       " 3   Shashi Tharoor explains why Congress is worth ...        3\n",
       " 8   You have seen Priyanka Gandhi everywhere’: Sha...        3,\n",
       " None)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Similarity(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765bb5c0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## TFIDF + Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3cecfdeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T08:49:27.468148Z",
     "start_time": "2022-03-17T08:49:27.447912Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Similarity(text):\n",
    "    text = set (text)\n",
    "\n",
    "    df= pd.DataFrame(data=text)\n",
    "    df=df.rename(columns={0:\"text\"})\n",
    "    \n",
    "    corpus = []\n",
    "\n",
    "    for i in range (0, len (df)):\n",
    "        # remvome puntuation \n",
    "        clean_text = re.sub('[^a-zA-Z]',' ',df[\"text\"][i])\n",
    "\n",
    "        # lower case \n",
    "        clean_text = clean_text.lower()\n",
    "\n",
    "        # split into token\n",
    "        clean_text = clean_text.split()\n",
    "\n",
    "        # join the text for leemitization\n",
    "        clean_text = nlp(\" \".join(clean_text))\n",
    "        # lemmitization\n",
    "        clean_text = [token.lemma_ for token in clean_text]\n",
    "\n",
    "        #stop word removal\n",
    "        clean_text = [word for word in clean_text if word not in stop_word]\n",
    "\n",
    "        # Joining the words in sentences\n",
    "        clean_text = ' '.join(clean_text)\n",
    "        corpus.append(clean_text)\n",
    "    \n",
    "    # Feature Extraction by TFIDF\n",
    "    tfidf = TfidfVectorizer()\n",
    "    corpus_tfidf= tfidf.fit_transform(corpus).toarray()\n",
    "    \n",
    "    sil_score_max = -1 #this is the minimum possible score\n",
    "\n",
    "    for n_clusters in range(2,len(df)):\n",
    "\n",
    "        cls= SpectralClustering(n_clusters= n_clusters,assign_labels='discretize',random_state=7).fit(corpus_tfidf)\n",
    "\n",
    "        labels = cls.labels_\n",
    "\n",
    "        sil_score = silhouette_score(corpus_tfidf,labels=labels)\n",
    "\n",
    "        if sil_score > sil_score_max:\n",
    "            sil_score_max = sil_score\n",
    "            best_cluster = n_clusters\n",
    "             \n",
    "    # use the best cluster for Spectral Clustering model\n",
    "    cls = SpectralClustering(n_clusters=best_cluster,assign_labels='discretize',random_state=7).fit(corpus_tfidf) \n",
    "    \n",
    "    \n",
    "    # labels for the clusters \n",
    "    df['Cluster']= cls.labels_\n",
    "    \n",
    "    return df.sort_values(by=[\"Cluster\"]), print(\"Best Cluster - {} Silhouette Score - {}\".format (best_cluster,sil_score_max))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "07a0c051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T08:49:28.296015Z",
     "start_time": "2022-03-17T08:49:27.997497Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cluster - 3 Silhouette Score - 0.12433158476654697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                                 text  Cluster\n",
       " 1   Bhagwant Mann swearing-in: ‘He was always in m...        0\n",
       " 4   Centre Rings Alarm Amid Covid Comeback in Chin...        0\n",
       " 6   Fourth wave of Covid-19 in China, Hong Kong ra...        0\n",
       " 7   Govt sounds Covid alert, calls for strict vigi...        0\n",
       " 10  Covid-19: Mansukh Mandaviya tells officials to...        0\n",
       " 2   PM Has Tremendous Vigour: Shashi Tharoor Credi...        1\n",
       " 3   Shashi Tharoor explains why Congress is worth ...        1\n",
       " 8   You have seen Priyanka Gandhi everywhere’: Sha...        1\n",
       " 0   Bhagwant Mann's Swearing-In Ceremony LIVE | Pu...        2\n",
       " 5   Punjab CM swearing-in LIVE updates: Bhagwant M...        2\n",
       " 9   Bhagwant Mann Swearing-In Live: AAP Leader Tak...        2,\n",
       " None)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Similarity(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f105f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Bert + Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "26f1bd24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T08:51:34.042502Z",
     "start_time": "2022-03-17T08:51:34.019564Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Similarity(text):\n",
    "    \n",
    "    text = set(text)\n",
    "\n",
    "    df= pd.DataFrame(data=text)\n",
    "    df=df.rename(columns={0:\"text\"})\n",
    "    \n",
    "    corpus = []\n",
    "\n",
    "    for i in range (0, len (df)):\n",
    "        # remvome puntuation \n",
    "        clean_text = re.sub('[^a-zA-Z]',' ',df[\"text\"][i])\n",
    "\n",
    "        # lower case \n",
    "        clean_text = clean_text.lower()\n",
    "\n",
    "        # split into token\n",
    "        clean_text = clean_text.split()\n",
    "\n",
    "        # join the text for leemitization\n",
    "        clean_text = nlp(\" \".join(clean_text))\n",
    "        # lemmitization\n",
    "        clean_text = [token.lemma_ for token in clean_text]\n",
    "\n",
    "        #stop word removal\n",
    "        clean_text = [word for word in clean_text if word not in stop_word]\n",
    "\n",
    "        # Joining the words in sentences\n",
    "        clean_text = ' '.join(clean_text)\n",
    "        corpus.append(clean_text)\n",
    "    \n",
    "    # Feature Extraction by Bert\n",
    "    corpus_word2vec= sbert_model.encode(corpus)\n",
    "    \n",
    "    sil_score_max = -1 #this is the minimum possible score\n",
    "\n",
    "    #to get the best clusters \n",
    "    for n_clusters in range(2,len(df)):\n",
    "\n",
    "        cls= KMeans(n_clusters= n_clusters,random_state=7)\n",
    "\n",
    "        cls.fit_transform(corpus_word2vec)\n",
    "\n",
    "        labels = cls.predict(corpus_word2vec)\n",
    "\n",
    "        sil_score = silhouette_score(corpus_word2vec,labels=labels)\n",
    "\n",
    "        if sil_score > sil_score_max:\n",
    "            sil_score_max = sil_score\n",
    "            best_cluster = n_clusters\n",
    "            best_cluster = n_clusters\n",
    "    \n",
    "    # use the best cluster number for Kmean model\n",
    "    cls = KMeans(n_clusters=best_cluster,random_state=7)\n",
    "    \n",
    "    cls.fit_transform(corpus_word2vec)\n",
    "    \n",
    "    cls.predict(corpus_word2vec)\n",
    "    \n",
    "    # labels for the clusters \n",
    "    df['Cluster']= cls.labels_\n",
    "\n",
    "       \n",
    "    return df.sort_values(by=[\"Cluster\"]), print(\"Best Cluster - {} Silhouette Score - {}\".format (best_cluster,sil_score_max))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ee7a1ceb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T08:51:36.340525Z",
     "start_time": "2022-03-17T08:51:34.502612Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cluster - 4 Silhouette Score - 0.23531098663806915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                                 text  Cluster\n",
       " 0   Bhagwant Mann's Swearing-In Ceremony LIVE | Pu...        0\n",
       " 1   Bhagwant Mann swearing-in: ‘He was always in m...        0\n",
       " 5   Punjab CM swearing-in LIVE updates: Bhagwant M...        0\n",
       " 9   Bhagwant Mann Swearing-In Live: AAP Leader Tak...        0\n",
       " 7   Govt sounds Covid alert, calls for strict vigi...        1\n",
       " 10  Covid-19: Mansukh Mandaviya tells officials to...        1\n",
       " 4   Centre Rings Alarm Amid Covid Comeback in Chin...        2\n",
       " 6   Fourth wave of Covid-19 in China, Hong Kong ra...        2\n",
       " 2   PM Has Tremendous Vigour: Shashi Tharoor Credi...        3\n",
       " 3   Shashi Tharoor explains why Congress is worth ...        3\n",
       " 8   You have seen Priyanka Gandhi everywhere’: Sha...        3,\n",
       " None)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Similarity(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c34906",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BERT Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3effd520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T09:08:10.783398Z",
     "start_time": "2022-03-17T09:08:10.762420Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Similarity(text):\n",
    "    \n",
    "    text = set(text)\n",
    "\n",
    "    df= pd.DataFrame(data=text)\n",
    "    df=df.rename(columns={0:\"text\"})\n",
    "    \n",
    "    corpus = []\n",
    "\n",
    "    for i in range (0, len (df)):\n",
    "        # remvome puntuation \n",
    "        clean_text = re.sub('[^a-zA-Z]',' ',df[\"text\"][i])\n",
    "\n",
    "        # lower case \n",
    "        clean_text = clean_text.lower()\n",
    "\n",
    "        # split into token\n",
    "        clean_text = clean_text.split()\n",
    "\n",
    "        # join the text for leemitization\n",
    "        clean_text = nlp(\" \".join(clean_text))\n",
    "        # lemmitization\n",
    "        clean_text = [token.lemma_ for token in clean_text]\n",
    "\n",
    "        #stop word removal\n",
    "        clean_text = [word for word in clean_text if word not in stop_word]\n",
    "\n",
    "        # Joining the words in sentences\n",
    "        clean_text = ' '.join(clean_text)\n",
    "        corpus.append(clean_text)\n",
    "    \n",
    "    # Feature Extraction by Bert\n",
    "    corpus_word2vec= sbert_model.encode(corpus)\n",
    "    \n",
    "    sil_score_max = -1 #this is the minimum possible score\n",
    "    \n",
    "    #to get the best clusters \n",
    "    for n_clusters in range(2,len(df)):\n",
    "\n",
    "        cls= SpectralClustering(n_clusters= n_clusters,assign_labels='discretize',random_state=40).fit(corpus_word2vec)\n",
    "\n",
    "        labels = cls.labels_\n",
    "\n",
    "        sil_score = silhouette_score(corpus_word2vec,labels=labels)\n",
    "\n",
    "        if sil_score > sil_score_max:\n",
    "            sil_score_max = sil_score\n",
    "            best_cluster = n_clusters\n",
    "    \n",
    "\n",
    "    # use the best cluster for Spectral Clustering model\n",
    "    cls = SpectralClustering(n_clusters=best_cluster,assign_labels='discretize',random_state=7).fit(corpus_word2vec) \n",
    "    \n",
    "    # labels for the clusters \n",
    "    df['Cluster']= cls.labels_\n",
    "    \n",
    "    return df.sort_values(by=[\"Cluster\"]), print(\"Best Cluster - {} Silhouette Score - {}\".format (best_cluster,sil_score_max))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f959b8ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-17T09:08:12.591472Z",
     "start_time": "2022-03-17T09:08:11.418346Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cluster - 5 Silhouette Score - 0.23600172996520996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                                                 text  Cluster\n",
       " 7   Govt sounds Covid alert, calls for strict vigi...        0\n",
       " 10  Covid-19: Mansukh Mandaviya tells officials to...        0\n",
       " 2   PM Has Tremendous Vigour: Shashi Tharoor Credi...        1\n",
       " 3   Shashi Tharoor explains why Congress is worth ...        1\n",
       " 8   You have seen Priyanka Gandhi everywhere’: Sha...        1\n",
       " 1   Bhagwant Mann swearing-in: ‘He was always in m...        2\n",
       " 4   Centre Rings Alarm Amid Covid Comeback in Chin...        3\n",
       " 6   Fourth wave of Covid-19 in China, Hong Kong ra...        3\n",
       " 0   Bhagwant Mann's Swearing-In Ceremony LIVE | Pu...        4\n",
       " 5   Punjab CM swearing-in LIVE updates: Bhagwant M...        4\n",
       " 9   Bhagwant Mann Swearing-In Live: AAP Leader Tak...        4,\n",
       " None)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Similarity(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8a1aeb",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "* Text Embedding with BERT and Spectral Clustering segregated the News Title really very well.\n",
    "* It even segregated the Covid News with Covid news related to China into 2 clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a00743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
